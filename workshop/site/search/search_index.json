{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to GenAI Stack Workshop","text":"<p>The GenAI Stack is a pre-configured, ready-to-code, and secure environment that makes it easy for developers to build and deploy GenAI applications.</p> <p>The GenAI Stack is a collaborative effort launched by Docker, Neo4j, LangChain, and Ollama at DockerCon 2023, aimed at streamlining the development of generative AI applications. This stack integrates several cutting-edge technologies to provide developers with a comprehensive toolkit for building AI-powered applications with ease.</p> <p>Key components of the GenAI Stack include:</p> <ol> <li> <p>Pre-configured Large Language Models (LLMs): The stack comes with pre-configured LLMs like Llama2, GPT-3.5, and GPT-4, enabling developers to kickstart their AI projects quickly.</p> </li> <li> <p>Ollama Management: Ollama facilitates the local management of open-source LLMs, streamlining the AI development process.</p> </li> <li> <p>Neo4j as the Default Database: Neo4j serves as the stack's default database, offering advanced graph and vector search capabilities. This enhances the speed and accuracy of AI/ML models by uncovering complex data patterns and relationships. Additionally, Neo4j acts as a long-term memory for these models, supporting more precise GenAI predictions and outcomes with its knowledge graphs.</p> </li> <li> <p>LangChain Orchestration: LangChain provides a framework for applications powered by LLMs, facilitating communication between the LLM, the application, and the database. It includes LangSmith for debugging, testing, evaluating, and monitoring LLM applications.</p> </li> <li> <p>Comprehensive Support: Docker and its partners offer a variety of tools, code templates, how-to guides, and best practices to support developers in their GenAI journey.</p> </li> </ol> <p>The GenAI Stack is designed to make AI/ML integration more accessible to developers, offering a ready-to-code and secure environment. By bringing together these technologies, the stack eliminates the need for developers to search for, assemble, and configure disparate technologies from different sources. The stack is available in Early Access and can be accessed from the Docker Desktop Learning Center or directly on GitHub.</p> <p>Gen-AI Stack Workshops are a series of workshops designed to teach developers how to build and deploy GenAI applications using the GenAI Stack. These workshops are ideal for developers who are interested in learning more about GenAI or who are looking for a hands-on introduction to the GenAI Stack.</p> <p>These hands-on labs will be a combination of theory and practical exercises.</p>"},{"location":"#github-sources","title":"GitHub Sources","text":"<p>The source code for this workshop is available here.</p>"},{"location":"#co-authors","title":"Co-Authors","text":"<ul> <li>Ajeet Singh Raina - DevRel @Docker</li> <li>Siddhant Agarwal - Developer Relations APAC @Neo4j</li> </ul>"},{"location":"#benefits-of-this-genai-stack-workshop","title":"Benefits of this GenAI Stack Workshop","text":"<ul> <li>Learn about GenAI and why it is important</li> <li>Learn how to use Docker to containerize and deploy GenAI applications</li> <li>Learn how to use Neo4j to store and manage knowledge graphs</li> <li>Learn how to use LangChain to generate text, translate languages, and write different kinds of creative content</li> <li>Learn how to use Ollama to train and deploy large language models</li> <li>Learn how to use the GenAI Stack to build and deploy GenAI applications</li> <li>Get hands-on experience with the GenAI Stack</li> <li>Network with other GenAI developers and trainers</li> </ul>"},{"location":"#applications-and-uses","title":"Applications and Uses","text":""},{"location":"#1-import-and-embed-data-from-stack-overflow-via-tags","title":"1. Import and Embed Data From Stack Overflow via Tags","text":""},{"location":"#2-support-agent-app-query-the-imported-data-via-a-chat-interface-using-vector-graph-search","title":"2. Support Agent App: Query the Imported Data via a Chat Interface Using Vector + Graph Search","text":""},{"location":"#3-generate-new-questions-in-the-style-of-highly-ranked-existing-ones","title":"3. Generate New Questions in the Style of Highly Ranked Existing Ones","text":""},{"location":"#4-read-local-pdf-and-ask-it-questions-fullstack-python-application","title":"4. Read local PDF and ask it questions. Fullstack Python application.","text":""},{"location":"lab1/best-practices/","title":"Best Practices","text":"<p>Generative AI (GenAI) is a rapidly developing field with the potential to revolutionize many industries. However, it is important to use GenAI responsibly and ethically. Here are some best practices for using GenAI:</p>"},{"location":"lab1/best-practices/#1-use-a-variety-of-training-data","title":"1. Use a variety of training data.","text":"<p>GenAI models are trained on data, so it is important to use a variety of data to reduce bias and improve accuracy. This includes using data from different sources, different demographics, and different viewpoints.</p>"},{"location":"lab1/best-practices/#2-monitor-the-output-of-genai-models-carefully","title":"2. Monitor the output of GenAI models carefully.","text":"<p>GenAI models can produce incorrect or biased results, so it is important to monitor their output carefully. This includes manually reviewing the output for errors and bias, and using automated tools to identify and remove harmful content.</p>"},{"location":"lab1/best-practices/#3-use-genai-models-in-a-responsible-and-ethical-way","title":"3. Use GenAI models in a responsible and ethical way.","text":"<p>GenAI models can be used to generate harmful content, such as misinformation and disinformation. It is important to use GenAI models in a responsible and ethical way, and to avoid using them to generate content that could harm others.</p>"},{"location":"lab1/best-practices/#4-be-transparent-about-the-use-of-genai","title":"4. Be transparent about the use of GenAI.","text":"<p>When using GenAI to generate content, it is important to be transparent about the fact that GenAI was used. This allows people to be aware of the limitations of the content and to make informed decisions about whether or not to trust it.</p>"},{"location":"lab1/best-practices/#5-establish-ethical-guidelines-for-the-use-of-genai","title":"5. Establish ethical guidelines for the use of GenAI.","text":"<p>Organizations should establish ethical guidelines for the use of GenAI. These guidelines should cover topics such as the use of GenAI to generate harmful content, the transparency of GenAI use, and the privacy and security of GenAI data.</p> <p>Here are some additional best practices for using GenAI:</p> <ul> <li>Use GenAI models that have been developed by reputable organizations.</li> <li>Keep your GenAI models up to date with the latest training data and security patches.</li> <li>Back up your GenAI models regularly.</li> <li>Have a plan for how to handle errors and bias in the output of your GenAI models.</li> <li>Be aware of the potential legal and regulatory implications of using GenAI.</li> </ul> <p>By following these best practices, you can help to ensure that GenAI is used in a responsible and ethical way.</p> <p>Here are some specific examples of how to apply these best practices in real-world situations:</p> <ul> <li>A company that is using GenAI to generate marketing materials should use a variety of training data that includes data from different demographics and viewpoints. They should also monitor the output of their GenAI models carefully to identify and remove any biased or harmful content.</li> <li>A news organization that is using GenAI to generate news articles should be transparent about the fact that GenAI was used. They should also have a plan for how to handle errors and bias in the output of their GenAI models.</li> <li>A government agency that is using GenAI to develop new policies should establish ethical guidelines for the use of GenAI. These guidelines should cover topics such as the use of GenAI to generate harmful content, the transparency of GenAI use, and the privacy and security of GenAI data.</li> </ul> <p>GenAI is a powerful new technology with the potential to revolutionize many industries. By following the best practices outlined above, you can help to ensure that GenAI is used in a responsible and ethical way.</p>"},{"location":"lab1/challenges/","title":"Current Challenges","text":"<p>Generative AI (GenAI) has the potential to revolutionize many industries, but there are still some challenges that need to be addressed before it can be widely adopted. Here are the top five GenAI challenges and how to overcome them:</p>"},{"location":"lab1/challenges/#1-limited-dataset-availability","title":"1. Limited dataset availability","text":"<p>GenAI models are trained on massive datasets of text and code. However, it can be difficult to find high-quality datasets that are relevant to the specific application. Additionally, some datasets may be biased or contain false information.</p>"},{"location":"lab1/challenges/#how-to-overcome-it","title":"How to overcome it:","text":"<p>Use multiple datasets: To reduce bias and improve accuracy, GenAI models should be trained on multiple datasets from different sources. Clean the data: Before training a GenAI model, the data should be cleaned to remove any false, biased, or contradicting information. This can be done manually or using automated tools. Use synthetic data: If high-quality datasets are not available, synthetic data can be generated. Synthetic data is artificially created data that is similar to real-world data.</p>"},{"location":"lab1/challenges/#2-explainability-and-interpretability","title":"2. Explainability and interpretability","text":"<p>GenAI models can be complex and difficult to understand. This makes it difficult to explain why a model makes a particular decision or generates a particular output.</p>"},{"location":"lab1/challenges/#how-to-overcome-it_1","title":"How to overcome it:","text":"<p>Develop interpretable models: Researchers are developing new GenAI models that are more interpretable. These models allow users to see how the model's inputs are mapped to its outputs. Use post-hoc explanation techniques: Post-hoc explanation techniques can be used to explain the predictions of existing GenAI models. These techniques work by analyzing the model's internal state and identifying the features that were most important in making the prediction.</p>"},{"location":"lab1/challenges/#3-computing-resources","title":"3. Computing resources","text":"<p>Training GenAI models requires a lot of computing resources. This can be a barrier to entry for small businesses and organizations.</p>"},{"location":"lab1/challenges/#how-to-overcome-it_2","title":"How to overcome it:","text":"<p>Use cloud computing: Cloud computing platforms provide access to powerful computing resources on demand. This can make it more affordable and accessible to train GenAI models. Use distributed training: Distributed training techniques can be used to train GenAI models on multiple machines. This can speed up the training process and reduce the cost.</p>"},{"location":"lab1/challenges/#4-legal-and-regulatory-frameworks","title":"4. Legal and regulatory frameworks","text":"<p>There are no clear legal and regulatory frameworks in place for the use of GenAI. This can create uncertainty and risk for businesses and organizations.</p>"},{"location":"lab1/challenges/#how-to-overcome-it_3","title":"How to overcome it:","text":"<p>Develop industry standards: Industry associations and organizations can work together to develop standards for the use of GenAI. These standards can help to ensure that GenAI is used in a responsible and ethical manner. Advocate for clear regulations: Businesses and organizations can advocate for clear and fair regulations for the use of GenAI. This will help to create a more predictable and stable environment for GenAI innovation.</p>"},{"location":"lab1/challenges/#5-ethical-considerations","title":"5. Ethical considerations","text":"<p>GenAI raises a number of ethical concerns, such as the potential for bias, misuse, and job displacement. It is important to address these concerns before GenAI is widely adopted.</p>"},{"location":"lab1/challenges/#how-to-overcome-it_4","title":"How to overcome it:","text":"<p>Develop ethical guidelines: Businesses and organizations should develop ethical guidelines for the use of GenAI. These guidelines should address how to avoid bias, misuse, and other potential harms. Educate the public: It is important to educate the public about the potential benefits and risks of GenAI. This will help to build trust and acceptance for this new technology.</p> <p>GenAI has the potential to revolutionize many industries, but there are still some challenges that need to be addressed before it can be widely adopted. By addressing these challenges, we can ensure that GenAI is used in a responsible and ethical manner to benefit society as a whole.# Challenges</p>"},{"location":"lab1/getting-started/","title":"Getting Started","text":""},{"location":"lab1/overview/","title":"Overview of GenAI","text":""},{"location":"lab1/overview/#what-is-genai","title":"What is GenAI?","text":"<p>Generative AI (GenAI) is a branch of artificial intelligence focused on creating new, original content by learning from vast amounts of data. This technology can generate text, images, audio, and more, mimicking the characteristics of the input data without directly replicating it. GenAI has seen significant advancements through models like Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and transformers, which have enabled the production of complex and realistic outputs, pushing the boundaries of content creation and automation.</p> <p>In real-world applications, GenAI is making strides across various industries, from entertainment and pharmaceuticals to manufacturing and finance. For instance, it's used in the entertainment industry for generating conceptual art and music for games and movies, while pharmaceutical companies leverage it for designing proteins for new medicines. Manufacturing sectors utilize GenAI for optimizing design processes in 3D printing and additive manufacturing, demonstrating GenAI's versatility in enhancing creativity, efficiency, and personalization across different fields.</p> <p>The advent of Large Language Models (LLMs) has been a game-changer in the field of GenAI, particularly in text generation. Models like GPT (Generative Pre-trained Transformer) series by OpenAI have showcased the ability to generate human-like text, offering applications in customer support, content creation, and more. These LLMs are trained on diverse internet text, enabling them to produce coherent and contextually relevant text outputs based on prompts. The integration of LLMs into GenAI applications exemplifies the technology's potential in transforming communication, content generation, and interactive experiences.</p> <p>These developments underscore the expansive potential of GenAI, from revolutionizing content creation to accelerating drug discovery and beyond, showcasing a future where AI-driven innovation is integral across sectors.</p>"},{"location":"lab1/overview/#what-is-genai-stack","title":"What is GenAI Stack?","text":"<p>The GenAI Stack is a set of Docker containers that are orchestrated by Docker Compose which includes a management tool for local LLMs (Ollama), a database for grounding (Neo4j), and GenAI apps based on LangChain. The containers provide a dev environment of a pre-built, support agent app with data import and response generation use-cases. You can experiment with importing different information in the knowledge graph and examine how the variety in underlying grounding information affects the generated responses by the LLM in the user interface.</p> <p>The GenAI Stack consists of:</p> <ul> <li>Application containers (the application logic in Python built with LangChain for the orchestration and Streamlit for the UI).</li> <li>Database container with vector index and graph search (Neo4j).</li> <li>LLM container Ollama (if you\u2019re on Linux). If you\u2019re on MacOS, install Ollama outside of Docker.</li> </ul> <p>These containers are tied together with Docker compose. Docker compose has a watch mode setup that rebuilds relevant containers any time you make a change to the application code, allowing for fast feedback loops and a good developer experience.</p>"},{"location":"lab1/solution/","title":"What problems does it solve?","text":"<p>Generative AI (GenAI) is a type of artificial intelligence that can create new content, such as text, images, and music. It is still under development, but it has the potential to revolutionize many industries and solve a wide range of problems.</p> <p>Here are some of the problems that GenAI can solve:</p>"},{"location":"lab1/solution/#content-creation","title":"Content creation","text":"<p>GenAI can be used to create high-quality content at scale. This can be useful for businesses that need to produce a lot of content, such as marketing materials, blog posts, and social media posts. GenAI can also be used to create personalized content for each user, such as product recommendations and news feeds.</p>"},{"location":"lab1/solution/#data-augmentation","title":"Data augmentation","text":"<p>GenAI can be used to generate synthetic data, which can be used to train machine learning models and improve their performance. This is especially useful for applications where it is difficult or expensive to collect real-world data. Creative tasks: GenAI can be used to automate creative tasks, such as writing poetry, generating music, and designing images. This can free up human creativity for more complex and strategic tasks.</p>"},{"location":"lab1/solution/#problem-solving","title":"Problem solving","text":"<p>GenAI can be used to solve complex problems by generating creative solutions. For example, GenAI can be used to design new drugs, develop new products, and optimize business processes.</p> <p>GenAI is still in its early stages of development, but it has the potential to solve a wide range of problems and revolutionize many industries. Here are a few specific examples of how GenAI is being used today:</p>"},{"location":"lab1/solution/#marketing","title":"Marketing","text":"<p>GenAI is being used to create personalized marketing campaigns and generate targeted content for each user.</p>"},{"location":"lab1/solution/#media","title":"Media","text":"<p>GenAI is being used to create personalized news feeds and generate realistic synthetic media, such as videos and images.</p>"},{"location":"lab1/solution/#healthcare","title":"Healthcare","text":"<p>GenAI is being used to design new drugs, develop personalized treatment plans, and diagnose diseases.</p>"},{"location":"lab1/solution/#finance","title":"Finance","text":"<p>GenAI is being used to detect fraud, develop trading strategies, and optimize risk management.</p>"},{"location":"lab1/solution/#science","title":"Science","text":"<p>GenAI is being used to accelerate scientific research by generating new hypotheses and designing experiments.</p>"},{"location":"lab2/docker-developer-workflow/","title":"Docker Developer Workflow","text":""},{"location":"lab2/genai-stack/","title":"docker-genai-sample","text":"<p>A simple GenAI app for Docker's Docs based on the GenAI Stack PDF Reader application.</p> <p>The generative AI (GenAI) guide teaches you how to containerize an existing GenAI application using Docker. In this guide, you\u2019ll learn how to:</p> <ul> <li>Containerize and run a Python-based GenAI application</li> <li>Set up a local environment to run the complete GenAI stack locally for development</li> <li>Start by containerizing an existing GenAI application.</li> </ul>"},{"location":"lab2/genai-stack/#whats-this-sample-app-all-about","title":"What's this sample app all about?","text":"<p>The sample application used in this guide is a modified version of the PDF Reader application from the GenAI Stack demo applications. The application is a full stack Python application that lets you ask questions about a PDF file.</p> <p>The application uses LangChain for orchestration, Streamlit for the UI, Ollama to run the LLM, and Neo4j to store vectors.</p> <p>Clone the sample application. Open a terminal, change directory to a directory that you want to work in, and run the following command to clone the repository:</p> <pre><code>$ git clone https://github.com/ajeetraina/docker-genai-sample\n</code></pre> <p>You should now have the following files in your <code>docker-genai-sample</code> directory.</p> <pre><code>\u251c\u2500\u2500 docker-genai-sample/\n\u2502 \u251c\u2500\u2500 .gitignore\n\u2502 \u251c\u2500\u2500 app.py\n\u2502 \u251c\u2500\u2500 chains.py\n\u2502 \u251c\u2500\u2500 env.example\n\u2502 \u251c\u2500\u2500 requirements.txt\n\u2502 \u251c\u2500\u2500 util.py\n\u2502 \u251c\u2500\u2500 LICENSE\n\u2502 \u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"lab2/genai-stack/#initialize-docker-assets","title":"Initialize Docker assets","text":"<p>Now that you have an application, you can use <code>docker init</code> to create the necessary Docker assets to containerize your application. Inside the <code>docker-genai-sample</code> directory, run the <code>docker init</code> command. <code>docker init</code> provides some default configuration, but you'll need to answer a few questions about your application. For example, this application uses Streamlit to run. Refer to the following <code>docker init</code> example and use the same answers for your prompts.</p> <pre><code>$ docker init\nWelcome to the Docker Init CLI!\n\nThis utility will walk you through creating the following files with sensible defaults for your project:\n  - .dockerignore\n  - Dockerfile\n  - compose.yaml\n  - README.Docker.md\n\nLet's get started!\n\n? What application platform does your project use? Python\n? What version of Python do you want to use? 3.11.4\n? What port do you want your app to listen on? 8000\n? What is the command to run your app? streamlit run app.py --server.address=0.0.0.0 --server.port=8000\n</code></pre> <p>You should now have the following contents in your <code>docker-genai-sample</code> directory.</p> <pre><code>\u251c\u2500\u2500 docker-genai-sample/\n\u2502 \u251c\u2500\u2500 .dockerignore\n\u2502 \u251c\u2500\u2500 .gitignore\n\u2502 \u251c\u2500\u2500 app.py\n\u2502 \u251c\u2500\u2500 chains.py\n\u2502 \u251c\u2500\u2500 compose.yaml\n\u2502 \u251c\u2500\u2500 env.example\n\u2502 \u251c\u2500\u2500 requirements.txt\n\u2502 \u251c\u2500\u2500 util.py\n\u2502 \u251c\u2500\u2500 Dockerfile\n\u2502 \u251c\u2500\u2500 LICENSE\n\u2502 \u251c\u2500\u2500 README.Docker.md\n\u2502 \u2514\u2500\u2500 README.md\n</code></pre> <p>To learn more about the files that <code>docker init</code> added, see the following:  - Dockerfile  - .dockerignore  - compose.yaml</p>"},{"location":"lab2/genai-stack/#run-the-application","title":"Run the application","text":"<p>Inside the <code>docker-genai-sample</code> directory, run the following command in a terminal.</p> <pre><code>$ docker compose up --build\n</code></pre> <p>Docker builds and runs your application. Depending on your network connection, it may take several minutes to download all the dependencies. You'll see a message like the following in the terminal when the application is running.</p> <pre><code>server-1  |   You can now view your Streamlit app in your browser.\nserver-1  |\nserver-1  |   URL: http://0.0.0.0:8000\nserver-1  |\n</code></pre> <p>Open a browser and view the application at http://localhost:8000. You should see a simple Streamlit application. The application may take a few minutes to download the embedding model. While the download is in progress, Running appears in the top-right corner.</p> <p></p> <p>The application requires a Neo4j database service and an LLM service to function. If you have access to services that you ran outside of Docker, specify the connection information and try it out. If you don't have the services running, continue with this guide to learn how you can run some or all of these services with Docker.</p>"},{"location":"lab2/genai-stack/#starting-neo4j-container","title":"Starting Neo4j container","text":"<pre><code> docker run -d --name database -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/password neo4j:5.11\n</code></pre>"},{"location":"lab2/genai-stack/#starting-ollama-container","title":"Starting Ollama container","text":"<pre><code> docker run -d \\\n  --name ollama \\\n  -p 11434:11434 \\\n  -v ollama_volume:/root/.ollama \\\n  ollama/ollama:latest\n</code></pre>"},{"location":"lab2/genai-stack/#accessing-the-application","title":"Accessing the application","text":"<p>You can populate the form using the following values:</p> <pre><code>Neo4j URI - neo4j://192.168.1.3:7687\nNEO4J_USERNAME=neo4j\nNEO4J_PASSWORD=password\nOLLAMA_BASE_URL=http://host.docker.internal:11434\nOPENAI Key=&lt;add it here&gt;\n</code></pre>"},{"location":"lab2/genai-stack/#chatting-with-the-pdf","title":"Chatting with the PDF","text":""},{"location":"lab2/getting-started/","title":"Getting Started with Docker Init","text":"<p>Example used to demonstrate <code>docker init</code> CLI for a simple Hello World Python Program</p>"},{"location":"lab2/getting-started/#clone-the-repository","title":"Clone the repository","text":"<pre><code> git clone https://github.com/dockersamples/docker-init-demos\n cd docker-init-demos/python\n</code></pre>"},{"location":"lab2/getting-started/#run-the-application","title":"Run the application","text":"<p>You can simply use <code>python3 app.py</code> command.</p> <p>This code defines a handler that responds to GET requests with the specified text and starts an HTTP server listening on port 8080. When you run the script, you can access the server at http://localhost:8080 and see the same message as the Python program.</p> <p>Those commands will start a http server listening on port <code>8080</code>  and if your request <code>http://localhost:8080</code> you'll see the following output: </p> <pre><code>\u276f curl http://localhost:8080\n\n          ##         .\n    ## ## ##        ==\n ## ## ## ## ##    ===\n/\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\\___/ ===\n{                       /  ===-\n\\______ O           __/\n \\    \\         __/\n  \\____\\_______/\n\n\nHello from Docker!\n</code></pre>"},{"location":"lab2/getting-started/#using-docker-init","title":"Using Docker init","text":""},{"location":"lab2/getting-started/#run-the-following-command","title":"Run the following command:","text":"<pre><code> docker init\n</code></pre> <p>This utility will walk you through creating the following files with sensible defaults for your project:   - .dockerignore   - Dockerfile   - docker-compose.yaml</p>"},{"location":"lab2/getting-started/#modify-the-dockerfile","title":"Modify the Dockerfile","text":"<pre><code>FROM python:3.8-alpine\nRUN mkdir /app\nADD . /app\nWORKDIR /app\nCMD [\"python3\", \"app.py\"]\n</code></pre>"},{"location":"lab2/getting-started/#modify-the-docker-compose-file","title":"Modify the Docker Compose file","text":"<pre><code>version: '3'\n\nservices:\n  app:\n    build: .\n    ports:\n      - \"8080:8080\"\n    command: python3 app.py\n</code></pre>"},{"location":"lab2/getting-started/#running-the-container-service","title":"Running the container service","text":"<pre><code> docker compose up -d --build\n</code></pre> <p>## Accessing the Python app</p> <p>``` curl localhost:8080</p> <pre><code>      ##         .\n## ## ##        ==\n</code></pre> <p>## ## ## ## ##    === /\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"_/ === {                       /  ===- ____ O           /               __/   _________/</p> <p>Hello from Docker! ```</p>"},{"location":"lab2/image-building/","title":"Docker Image Building and Best Practices","text":""},{"location":"lab2/image-building/#introducing-docker-init","title":"Introducing Docker Init","text":"<p>Introduced for the first time in Docker Desktop 4.18, the new docker init CLI generates Docker assets for projects, making it easier to create Docker images and containers. When you run the docker init command in your project directory, it will guide you through the creation of the necessary files for your project with sensible defaults. These files include:</p> <pre><code>.dockerignore\nDockerfile\ndocker-compose.yaml\n</code></pre> <p>The docker init command also allows you to choose the application platform that your project uses and the relative directory of your main package. </p>"},{"location":"lab2/image-building/#whos-this-for","title":"Who\u2019s this for?","text":"<p>This feature is targeted at developers who want to quickly create and manage Docker assets without having to manually configure everything. </p> <p>Note: Currently, the CLI is in beta phase. </p>"},{"location":"lab2/image-building/#benefits-of-docker-init","title":"Benefits of Docker Init","text":"<p>The advantages of using the docker init command include:</p> <ul> <li>Simplified Docker asset creation: The command streamlines the creation of necessary Docker files, reducing the chances of errors and ensuring that best practices are followed.</li> <li>Saves time and effort: With the default settings and guided prompts, users can quickly create Docker assets without the need for extensive knowledge of Docker or its syntax.</li> <li>Better project organization: The generated files provide a standardized and organized structure for the project, making it easier for developers to maintain and update the project over time.</li> <li>Enhanced portability: By using Docker assets, projects become more portable across different environments, making it easier to move the project from development to production.</li> </ul> <p></p>"},{"location":"lab2/inner-loop-developer/","title":"Inner-loop Developer Workflow","text":""},{"location":"lab2/what-is-docker/","title":"What is Docker","text":"<p>Developing apps today requires so much more than writing code. Multiple languages, frameworks, architectures, and discontinuous interfaces between tools for each lifecycle stage creates enormous complexity. Docker simplifies and accelerates your workflow, while giving developers the freedom to innovate with their choice of tools, application stacks, and deployment environments for each project.</p> <p>In 2013, Docker introduced what would become the industry standard for containers. Containers are a standardized unit of software that allows developers to isolate their app from its environment, solving the \u201cit works on my machine\u201d headache. For millions of developers today, Docker is the de facto standard to build and share containerized apps \u2013 from desktop, to the cloud. We are building on our unique connected experience from code to cloud for developers and developer teams.</p> <p>Docker has been around for over 10-years. We started in the container space focused on making it easier for organizations to modernize with container technology. Over the years we have evolved our initial offering to meet the needs of modern developers, focusing on enabling developers to build container based applications locally. </p>"},{"location":"lab2/what-is-docker/#overview-of-docker-desktop","title":"Overview of Docker Desktop","text":"<p>Docker Desktop is the easiest way for developers using containers in production to edit, run, test, and share containerized apps locally on Linux, Windows, and macOS machines. Docker Desktop works out-of-the-box \u2014 meaning it comes with the entire environment needed to develop and run Linux, Windows, and macOS containers locally (on the developer\u2019s laptop). Docker Desktop also handles many of the tedious and complex tasks associated with setting up containers. This allows developers to continue focusing on what they love and do best \u2014 writing code \u2014 instead of spending hours setting up and maintaining Docker locally (i.e., updating the VM, networking, and file sharing mapping between the host and the VM and all the tooling needed to run Docker locally). </p>"},{"location":"lab2/what-is-docker/#docker-is-focused-on-developer-success","title":"Docker is focused on Developer Success","text":"<p>Docker Desktop is a powerful tool designed to simplify and streamline the development and deployment of applications using Docker containers. Let's break down the key points mentioned in the description:</p> <p></p>"},{"location":"lab2/what-is-docker/#speed","title":"Speed","text":"<p>Docker Desktop helps developers maximize their productivity by reducing the time spent on setup and configuration. With Docker, developers can easily package their applications and all their dependencies into containers, allowing for a consistent and reproducible development environment. This eliminates the need for complex manual setups and ensures that everyone on the team can have the same development environment, minimizing the setup overhead.</p>"},{"location":"lab2/what-is-docker/#security","title":"Security","text":"<p>Docker Desktop is designed to provide non-intrusive and actionable security features. It allows developers to identify and address security vulnerabilities during the development process, known as the \"inner loop,\" rather than waiting for later stages like continuous integration (CI) or production. Docker also provides features like container isolation, which enhances security by ensuring that applications run in isolated environments with restricted access to the host system.</p>"},{"location":"lab2/what-is-docker/#choice","title":"Choice","text":"<p>Docker Desktop empowers developers with the freedom to explore and experiment with various technologies. Docker's containerization approach allows developers to use different tools and technologies for different parts of their applications without conflicts or compatibility issues. Developers are not limited to monolithic and \"one-size-fits-all\" development environments; instead, they can choose the best tools for their specific use cases. Overall, Docker Desktop's features cater to developers' needs for a fast and efficient development process, enhanced security practices, and the flexibility to use diverse technologies based on the requirements of their projects. This combination of speed, security, and choice makes Docker Desktop a popular choice among developers looking to containerize and manage their applications effectively.</p>"},{"location":"lab3/cypher/","title":"Cypher Query Language","text":"<p>Cypher is a declarative graph query language that allows for efficient querying and updating of graph databases, such as those managed by Neo4j. It's designed to be intuitive and to closely resemble English, making it easier to express complex queries and manipulations of graph data. It uses an ASCII-art style syntax consisting of brackets, dashes and arrows.</p> <p></p> <p>You can use Cypher to perform a variety of operations on a graph database, including:</p> <ul> <li>Creating nodes and relationships: You can define new nodes and the relationships between them.</li> <li>Querying data: Cypher allows you to retrieve nodes, relationships, and properties based on specific criteria.</li> <li>Updating data: You can use Cypher to modify existing nodes and relationships, including adding or updating properties.</li> <li>Deleting data: Nodes, relationships, and properties can be removed from the graph.</li> </ul> <p>Cypher queries typically involve specifying patterns that describe the shape of the data you're interested in. These patterns can include nodes, relationships, and the directions of those relationships.</p>"},{"location":"lab3/cypher/#cypher-syntax","title":"Cypher Syntax","text":"<p>Let's dive deeper into Cypher, providing some syntax examples and explanations for common operations you can perform on a graph database using this language.</p>"},{"location":"lab3/cypher/#creating-nodes-and-relationships","title":"Creating Nodes and Relationships","text":"<p>To create a node, you use the <code>CREATE</code> statement. Nodes can have labels (which can be thought of as types or categories) and properties (key-value pairs).</p> <pre><code>CREATE (n:Person {name: 'Alice', age: 30})\n</code></pre> <p>This creates a node with the label <code>Person</code> and two properties: <code>name</code> with the value 'Alice' and <code>age</code> with the value 30.</p> <p>To create a relationship between two nodes, you also use the <code>CREATE</code> statement. Relationships have types and can also have properties.</p> <pre><code>CREATE (n:Person {name: 'Alice'})-[:FRIEND_OF {since: 2021}]-&gt;(m:Person {name: 'Bob'})\n</code></pre> <p>This creates two <code>Person</code> nodes and a <code>FRIEND_OF</code> relationship from Alice to Bob, with a property since indicating the year they became friends.</p>"},{"location":"lab3/cypher/#querying-data","title":"Querying Data","text":"<p>To retrieve data, you use the <code>MATCH</code> statement, which allows you to specify patterns to find in the graph. You can also use <code>WHERE</code> to filter results, and <code>RETURN</code> to specify what to return.</p> <pre><code>MATCH (n:Person {name: 'Alice'})\nRETURN n\n</code></pre> <p>This query looks for a <code>Person</code> node with the name 'Alice' and returns it.</p> <p>You can also query relationships:</p> <pre><code>MATCH (n:Person)-[r:FRIEND_OF]-&gt;(m:Person)\nWHERE n.name = 'Alice'\nRETURN n, r, m\n</code></pre> <p>This finds <code>Person</code> nodes that are friends of Alice and returns the nodes and the relationships.</p>"},{"location":"lab3/cypher/#updating-data","title":"Updating Data","text":"<p>To update data, you can use <code>SET</code> to add or change properties of nodes and relationships.</p> <pre><code>MATCH (n:Person {name: 'Alice'})\nSET n.age = 31\nRETURN n\n</code></pre> <p>This updates Alice's age to 31.</p>"},{"location":"lab3/cypher/#deleting-data","title":"Deleting Data","text":"<p>To delete nodes and relationships, you use the <code>DELETE</code> statement.</p> <pre><code>MATCH (n:Person {name: 'Alice'})\nDELETE n\n</code></pre> <p>This deletes the <code>Person</code> node with the name 'Alice'. Note that you must delete or detach all relationships of a node before you can delete the node itself.</p>"},{"location":"lab3/cypher/#aggregation-and-ordering","title":"Aggregation and Ordering","text":"<p>Cypher supports aggregation functions similar to SQL, as well as ordering results.</p> <pre><code>MATCH (n:Person)\nRETURN n.age, COUNT(n) AS num_people\nORDER BY n.age\n</code></pre> <p>This query returns the ages of all <code>Person</code> nodes and the count of people for each age, ordered by age.</p>"},{"location":"lab3/cypher/#combining-operations","title":"Combining Operations","text":"<p>You can combine these operations to perform complex queries and updates. For example, you might want to find all friends of Alice, increment their ages, and return the updated nodes:</p> <pre><code>MATCH (n:Person {name: 'Alice'})-[:FRIEND_OF]-&gt;(friend:Person)\nSET friend.age = friend.age + 1\nRETURN friend\n</code></pre> <p>This finds all of Alice's friends, increments their ages by 1, and returns the updated friend nodes.</p> <p>Cypher's syntax and operations are designed to be intuitive for dealing with graph structures, making it easier to express complex queries involving nodes, relationships, and properties.</p>"},{"location":"lab3/intro/","title":"Introduction to Neo4j and Knowledge Graphs","text":""},{"location":"lab3/intro/#introduction-to-neo4j","title":"Introduction to Neo4j","text":"<p>Neo4j is a highly popular graph database management system, designed for storing and querying interconnected data. Unlike traditional relational databases that store data in tables, Neo4j is based on graph theory, using nodes, relationships, and properties to represent and store data. The key components of Neo4j include:</p> <ul> <li>Nodes: Entities or objects such as people, businesses, accounts, or any item you want to track.</li> <li>Relationships: Connections between nodes, which can be directed and named and may carry properties. These relationships provide context and add richness to the data model.</li> <li>Properties: Key-value pairs that store data associated with nodes and relationships, allowing for the storage of detailed information about the entities in the graph.</li> </ul> <p></p> <p>Neo4j is particularly well-suited for applications that require complex queries and analysis of connected data, such as social networks, recommendation engines, fraud detection, and more. Its Cypher query language is specially designed for querying graph data in an expressive and efficient manner.</p> <p>You can get started with Neo4j with AuraDB and for more learning content check out Free, Self-Paced, Hands-on Online Training Courses at Neo4j GraphAcademy.</p>"},{"location":"lab3/intro/#introduction-to-knowledge-graphs","title":"Introduction to Knowledge Graphs","text":"<p>Knowledge Graphs are a form of graph-based data representation that organize and integrate information in a way that makes it possible for computers to understand and interpret. They consist of nodes representing entities (such as people, places, concepts, and objects) and edges representing the relationships between these entities. Knowledge graphs are used to store interconnected descriptions of entities with free-form semantics, allowing for a dynamic and interconnected representation of knowledge.</p> <p></p> <p>The power of knowledge graphs lies in their flexibility and the richness of the semantics they can capture, making them an essential tool for many applications, including:</p> <ul> <li>Semantic Search: Enhancing search capabilities by understanding the context and relationships between terms.</li> <li>Recommendation Systems: Offering personalized recommendations based on the interconnected nature of user interests and behavior.</li> <li>Natural Language Processing (NLP): Improving the understanding of human language by mapping out relationships and entities in text.</li> <li>Data Integration: Unifying data from multiple sources and formats, providing a holistic view of information.</li> </ul> <p>Knowledge graphs can be implemented using various storage technologies, including graph databases like Neo4j, which provides a robust platform for managing complex, connected data structures.</p>"},{"location":"lab3/intro/#relationship-between-neo4j-and-knowledge-graphs","title":"Relationship between Neo4j and Knowledge Graphs","text":"<p>Neo4j can be used as the underlying database technology for building knowledge graphs. Its graph-based model aligns naturally with the structure of knowledge graphs, enabling efficient storage, querying, and management of interconnected data. By leveraging Neo4j, developers can create powerful applications that harness the full potential of knowledge graphs, from complex data analysis to AI-driven insights.</p> <p>In summary, Neo4j and Knowledge Graphs represent a powerful paradigm for managing and analyzing interconnected data. They offer a flexible and semantically rich way to model relationships and insights that are difficult to capture with traditional database systems, opening up new possibilities for understanding and leveraging data in various domains.</p>"},{"location":"lab6/using-docker-compose/","title":"Using Docker Compose","text":"<p>Follow the instructions to run a complete GenAI Stack using Docker Compose</p>"},{"location":"lab6/using-docker-compose/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Pre-req</li> <li>Step 1. Install Ollama on Mac OS</li> <li>Step 2. Create OpenAI Secret API Keys</li> <li>Step 3. Sign up for LangChain Beta for API Keys</li> <li>Step 4. Clone the GenAI Repo</li> <li>Step 5. Create .env file</li> <li>Step 6. Bring up Compose Services</li> <li>Step 7. Viewing the services on Docker Dashboard</li> <li>Step 8. Accessing the app</li> <li>Step 9. Accessing the Neo4j </li> <li>Step 10. Accessing GenAI Stack PDF Bot </li> </ul>"},{"location":"lab6/using-docker-compose/#prereq","title":"Prereq","text":"<ul> <li>Install Docker Desktop 4.23.0</li> </ul>"},{"location":"lab6/using-docker-compose/#step-1-install-ollama-on-mac-os","title":"Step 1. Install Ollama on Mac OS","text":"<p>Visit this link to download and install Ollama on Macbook. Please note that currently, Windows is not supported by Ollama, so Windows users need to generate a OpenAI API key and configure the stack to use gpt-3.5 or gpt-4 in the .env file.</p> <p></p> <p>Choose your preferrable operating system. </p> <p></p>"},{"location":"lab6/using-docker-compose/#step-2-create-openai-secret-api-keys","title":"Step 2. Create OpenAI Secret API Keys","text":"<p>Visit this link to create your new OpenAI Secret API Keys.</p>"},{"location":"lab6/using-docker-compose/#step-3-sign-up-for-langchain-beta-for-api-keys","title":"Step 3. Sign Up for LangChain Beta for API Keys","text":"<p>Visit this link in order to create Langchain Endpoint and API Keys. You will need the following information</p> <pre><code>LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\nLANGCHAIN_TRACING_V2=true # false\nLANGCHAIN_PROJECT=default\nLANGCHAIN_API_KEY=ls__cbabccXXXXXX\n</code></pre>"},{"location":"lab6/using-docker-compose/#step-4-clone-the-repository","title":"Step 4. Clone the repository","text":"<pre><code> git clone https://github.com/docker/genai-stack\n cd genai-stack\n</code></pre>"},{"location":"lab6/using-docker-compose/#step-5-create-env-file","title":"Step 5. Create .env file","text":"<pre><code>cat .env \nOPENAI_API_KEY=sk-EsNJzI5uMBCXXXXXXXX\nOLLAMA_BASE_URL=http://host.docker.internal:11434\nNEO4J_URI=neo4j://database:7687\nNEO4J_USERNAME=neo4j\nNEO4J_PASSWORD=password\nLLM=llama2 #or any Ollama model tag, or gpt-4 or gpt-3.5\nEMBEDDING_MODEL=sentence_transformer #or openai or ollama\n\nLANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\nLANGCHAIN_TRACING_V2=true # false\nLANGCHAIN_PROJECT=default\nLANGCHAIN_API_KEY=ls__cbabccXXXXXX\n</code></pre> <p>Don't forget to change \"localhost\" to \"database\" under NEO4J_URI entry.</p>"},{"location":"lab6/using-docker-compose/#step-6-bring-up-compose-services","title":"Step 6. Bring up Compose services","text":"<pre><code> docker compose up -d --build\n</code></pre> <pre><code>..\n..\ngenai-stack-bot-1         |   You can now view your Streamlit app in your browser.\ngenai-stack-bot-1         |\ngenai-stack-bot-1         |   URL: http://0.0.0.0:8501\ngenai-stack-bot-1         |\ngenai-stack-pdf_bot-1     |\ngenai-stack-pdf_bot-1     |   You can now view your Streamlit app in your browser.\ngenai-stack-pdf_bot-1     |\ngenai-stack-pdf_bot-1     |   URL: http://0.0.0.0:8503\ngenai-stack-pdf_bot-1     |\ngenai-stack-loader-1      |\ngenai-stack-loader-1      |   You can now view your Streamlit app in your browser.\ngenai-stack-loader-1      |\ngenai-stack-loader-1      |   URL: http://0.0.0.0:8502\ngenai-stack-loader-1      |\n</code></pre>"},{"location":"lab6/using-docker-compose/#step-7-viewing-the-services-on-docker-dashboard","title":"Step 7. Viewing the Services on Docker Dashboard","text":""},{"location":"lab6/using-docker-compose/#step-8-accessing-the-app","title":"Step 8. Accessing the app","text":"<p>Visit http://0.0.0.0:8502 to access the following:</p> <p></p> <p>Click \"Import\". It will take a minute or two to run the import. Most of the time is spent generating the embeddings. After or during the import you can click the link to <code>http://localhost:7474</code> and log in with username \u201cneo4j\u201d and password \u201cpassword\u201d as configured in docker compose. There, you can see an overview in the left sidebar and show some connected data by clicking on the \u201cpill\u201d with the counts.</p> <p>The data loader will import the graph using the following schema.</p> <p></p>"},{"location":"lab6/using-docker-compose/#result","title":"Result:","text":"<p>The graph schema for Stack Overflow consists of nodes representing Questions, Answers, Users, and Tags. Users are linked to Questions they\u2019ve asked via the \u201cASKED\u201d relationship and to Answers they\u2019ve provided with the \u201cANSWERS\u201d relationship. Each Answer is also inherently associated with a specific Question. Furthermore, Questions are categorized by their relevant topics or technologies using the \u201cTAGGED\u201d relationship connecting them to Tags.</p>"},{"location":"lab6/using-docker-compose/#step-9-accessing-the-neo4j","title":"Step 9. Accessing the Neo4j","text":"<p>As instructed, open <code>http://localhost:7474</code> and log in with username \u201cneo4j\u201d and password \u201cpassword\u201d as configured in docker compose.</p> <p></p>"},{"location":"lab6/using-docker-compose/#step-10-query-the-imported-data-via-a-chat-interface-using-vector-graph-search","title":"Step 10. Query the Imported Data via a Chat Interface Using Vector + Graph Search","text":"<p>This application server on <code>http://localhost:8501</code> has the classic LLM chat UI and lets the user ask questions and get answers.</p> <p>There\u2019s a switch called RAG mode where the user can rely either completely on the LLMs trained knowledge (RAG: Disabled), or the more capable (RAG: Enabled) mode where the application uses similarity search using text embedding and graph queries to find the most relevant questions and answers in the database.</p> <p>Click \"Highly ranked questions\"</p>"},{"location":"lab6/using-docker-compose/#step-11-accessing-genai-stack-pdf-bot","title":"Step 11. Accessing GenAI Stack PDF Bot","text":"<p>Open <code>http://0.0.0.0:8503/</code> on the browser to access the PDF Bot that allows you to chat with your PDF file.</p> <p></p> <p>In order to test drive, I uploaded my latest resume and asked a quick question.  It responded back with the right answer. Amazing !!</p>"},{"location":"prereq/prerequisites/","title":"Prerequisites:","text":""},{"location":"prereq/prerequisites/#1-docker-desktop","title":"1. Docker Desktop","text":"<p>Download and Install Docker Desktop on your system. Make sure you are using Docker Desktop v4.27.2 and above.</p> <ul> <li>Apple Chip</li> <li>Intel Chip</li> <li>Windows</li> <li>Linux</li> </ul>"},{"location":"prereq/prerequisites/#enabling-wsl-2-based-engine-on-docker-desktop-for-windows","title":"Enabling WSL 2 based engine on Docker Desktop for Windows","text":"<p>In case you're using Windows 11, you will need to enable WSL 2 by opening Docker Desktop &gt; Settings &gt; Resources &gt; WSL Integration</p> <p></p>"},{"location":"prereq/prerequisites/#2-ollama","title":"2. Ollama","text":"<p>Download and Install Ollama on your system.</p> <p>Note: For Windows Users, if you have antivirus installed on your system Ollama installation might be flagged as virus. It is advisable to disbale your antivirus/firewall before installation and enable it back once the installation is complete.</p>"}]}