{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to GenAI Stack Workshop","text":"<p>The GenAI Stack is a pre-configured, ready-to-code, and secure environment that makes it easy for developers to build and deploy GenAI applications.</p> <p>Gen-AI Stack Workshops are a series of workshops designed to teach developers how to build and deploy GenAI applications using the GenAI Stack. These workshops are ideal for developers who are interested in learning more about GenAI or who are looking for a hands-on introduction to the GenAI Stack.</p> <p>These hands-on labs will be a combination of theory and practical exercises.</p>"},{"location":"#github-sources","title":"GitHub Sources","text":"<p>The source code for this workshop is available here</p>"},{"location":"#co-authors","title":"Co-Authors","text":"<ul> <li>Ajeet Singh Raina - DevRel @Docker</li> <li>Siddhant Agarwal - Tech Community Manager @Neo4j</li> </ul>"},{"location":"#benefits-of-genai-stack-workshop","title":"Benefits of GenAI Stack Workshop","text":"<ul> <li>Learn about GenAI and why it is important</li> <li>Learn how to use the GenAI Stack to build and deploy GenAI applications</li> <li>Learn how to use Docker to containerize and deploy GenAI applications</li> <li>Learn how to use Neo4j to store and manage knowledge graphs</li> <li>Learn how to use LangChain to generate text, translate languages, and write different kinds of creative content</li> <li>Learn how to use Ollama to train and deploy large language models</li> <li>Get hands-on experience with the GenAI Stack</li> <li>Network with other GenAI developers and trainers</li> </ul>"},{"location":"#applications-and-uses","title":"Applications and Uses","text":""},{"location":"#1-import-and-embed-data-from-stack-overflow-via-tags","title":"1. Import and Embed Data From Stack Overflow via Tags","text":""},{"location":"#2-support-agent-app-query-the-imported-data-via-a-chat-interface-using-vector-graph-search","title":"2. Support Agent App: Query the Imported Data via a Chat Interface Using Vector + Graph Search","text":""},{"location":"#3-generate-new-questions-in-the-style-of-highly-ranked-existing-ones","title":"3. Generate New Questions in the Style of Highly Ranked Existing Ones","text":""},{"location":"#4-read-local-pdf-and-ask-it-questions-fullstack-python-application","title":"4. Read local PDF and ask it questions. Fullstack Python application.","text":""},{"location":"lab1/best-practices/","title":"Best Practices","text":"<p>Generative AI (GenAI) is a rapidly developing field with the potential to revolutionize many industries. However, it is important to use GenAI responsibly and ethically. Here are some best practices for using GenAI:</p>"},{"location":"lab1/best-practices/#1-use-a-variety-of-training-data","title":"1. Use a variety of training data.","text":"<p>GenAI models are trained on data, so it is important to use a variety of data to reduce bias and improve accuracy. This includes using data from different sources, different demographics, and different viewpoints.</p>"},{"location":"lab1/best-practices/#2-monitor-the-output-of-genai-models-carefully","title":"2. Monitor the output of GenAI models carefully.","text":"<p>GenAI models can produce incorrect or biased results, so it is important to monitor their output carefully. This includes manually reviewing the output for errors and bias, and using automated tools to identify and remove harmful content.</p>"},{"location":"lab1/best-practices/#3-use-genai-models-in-a-responsible-and-ethical-way","title":"3. Use GenAI models in a responsible and ethical way.","text":"<p>GenAI models can be used to generate harmful content, such as misinformation and disinformation. It is important to use GenAI models in a responsible and ethical way, and to avoid using them to generate content that could harm others.</p>"},{"location":"lab1/best-practices/#4-be-transparent-about-the-use-of-genai","title":"4. Be transparent about the use of GenAI.","text":"<p>When using GenAI to generate content, it is important to be transparent about the fact that GenAI was used. This allows people to be aware of the limitations of the content and to make informed decisions about whether or not to trust it.</p>"},{"location":"lab1/best-practices/#5-establish-ethical-guidelines-for-the-use-of-genai","title":"5. Establish ethical guidelines for the use of GenAI.","text":"<p>Organizations should establish ethical guidelines for the use of GenAI. These guidelines should cover topics such as the use of GenAI to generate harmful content, the transparency of GenAI use, and the privacy and security of GenAI data.</p> <p>Here are some additional best practices for using GenAI:</p> <ul> <li>Use GenAI models that have been developed by reputable organizations.</li> <li>Keep your GenAI models up to date with the latest training data and security patches.</li> <li>Back up your GenAI models regularly.</li> <li>Have a plan for how to handle errors and bias in the output of your GenAI models.</li> <li>Be aware of the potential legal and regulatory implications of using GenAI.</li> </ul> <p>By following these best practices, you can help to ensure that GenAI is used in a responsible and ethical way.</p> <p>Here are some specific examples of how to apply these best practices in real-world situations:</p> <ul> <li>A company that is using GenAI to generate marketing materials should use a variety of training data that includes data from different demographics and viewpoints. They should also monitor the output of their GenAI models carefully to identify and remove any biased or harmful content.</li> <li>A news organization that is using GenAI to generate news articles should be transparent about the fact that GenAI was used. They should also have a plan for how to handle errors and bias in the output of their GenAI models.</li> <li>A government agency that is using GenAI to develop new policies should establish ethical guidelines for the use of GenAI. These guidelines should cover topics such as the use of GenAI to generate harmful content, the transparency of GenAI use, and the privacy and security of GenAI data.</li> </ul> <p>GenAI is a powerful new technology with the potential to revolutionize many industries. By following the best practices outlined above, you can help to ensure that GenAI is used in a responsible and ethical way.</p>"},{"location":"lab1/challenges/","title":"Current Challenges","text":"<p>Generative AI (GenAI) has the potential to revolutionize many industries, but there are still some challenges that need to be addressed before it can be widely adopted. Here are the top five GenAI challenges and how to overcome them:</p>"},{"location":"lab1/challenges/#1-limited-dataset-availability","title":"1. Limited dataset availability","text":"<p>GenAI models are trained on massive datasets of text and code. However, it can be difficult to find high-quality datasets that are relevant to the specific application. Additionally, some datasets may be biased or contain false information.</p>"},{"location":"lab1/challenges/#how-to-overcome-it","title":"How to overcome it:","text":"<p>Use multiple datasets: To reduce bias and improve accuracy, GenAI models should be trained on multiple datasets from different sources. Clean the data: Before training a GenAI model, the data should be cleaned to remove any false, biased, or contradicting information. This can be done manually or using automated tools. Use synthetic data: If high-quality datasets are not available, synthetic data can be generated. Synthetic data is artificially created data that is similar to real-world data.</p>"},{"location":"lab1/challenges/#2-explainability-and-interpretability","title":"2. Explainability and interpretability","text":"<p>GenAI models can be complex and difficult to understand. This makes it difficult to explain why a model makes a particular decision or generates a particular output.</p>"},{"location":"lab1/challenges/#how-to-overcome-it_1","title":"How to overcome it:","text":"<p>Develop interpretable models: Researchers are developing new GenAI models that are more interpretable. These models allow users to see how the model's inputs are mapped to its outputs. Use post-hoc explanation techniques: Post-hoc explanation techniques can be used to explain the predictions of existing GenAI models. These techniques work by analyzing the model's internal state and identifying the features that were most important in making the prediction.</p>"},{"location":"lab1/challenges/#3-computing-resources","title":"3. Computing resources","text":"<p>Training GenAI models requires a lot of computing resources. This can be a barrier to entry for small businesses and organizations.</p>"},{"location":"lab1/challenges/#how-to-overcome-it_2","title":"How to overcome it:","text":"<p>Use cloud computing: Cloud computing platforms provide access to powerful computing resources on demand. This can make it more affordable and accessible to train GenAI models. Use distributed training: Distributed training techniques can be used to train GenAI models on multiple machines. This can speed up the training process and reduce the cost.</p>"},{"location":"lab1/challenges/#4-legal-and-regulatory-frameworks","title":"4. Legal and regulatory frameworks","text":"<p>There are no clear legal and regulatory frameworks in place for the use of GenAI. This can create uncertainty and risk for businesses and organizations.</p>"},{"location":"lab1/challenges/#how-to-overcome-it_3","title":"How to overcome it:","text":"<p>Develop industry standards: Industry associations and organizations can work together to develop standards for the use of GenAI. These standards can help to ensure that GenAI is used in a responsible and ethical manner. Advocate for clear regulations: Businesses and organizations can advocate for clear and fair regulations for the use of GenAI. This will help to create a more predictable and stable environment for GenAI innovation.</p>"},{"location":"lab1/challenges/#5-ethical-considerations","title":"5. Ethical considerations","text":"<p>GenAI raises a number of ethical concerns, such as the potential for bias, misuse, and job displacement. It is important to address these concerns before GenAI is widely adopted.</p>"},{"location":"lab1/challenges/#how-to-overcome-it_4","title":"How to overcome it:","text":"<p>Develop ethical guidelines: Businesses and organizations should develop ethical guidelines for the use of GenAI. These guidelines should address how to avoid bias, misuse, and other potential harms. Educate the public: It is important to educate the public about the potential benefits and risks of GenAI. This will help to build trust and acceptance for this new technology.</p> <p>GenAI has the potential to revolutionize many industries, but there are still some challenges that need to be addressed before it can be widely adopted. By addressing these challenges, we can ensure that GenAI is used in a responsible and ethical manner to benefit society as a whole.# Challenges</p>"},{"location":"lab1/getting-started/","title":"Getting Started","text":""},{"location":"lab1/overview/","title":"Overview of GenAI","text":""},{"location":"lab1/overview/#what-is-genai-stack","title":"What is GenAI Stack?","text":"<p>The GenAI Stack is a set of Docker containers that are orchestrated by Docker Compose which includes a management tool for local LLMs (Ollama), a database for grounding (Neo4j), and GenAI apps based on LangChain. The containers provide a dev environment of a pre-built, support agent app with data import and response generation use-cases. You can experiment with importing different information in the knowledge graph and examine how the variety in underlying grounding information affects the generated responses by the LLM in the user interface.</p> <p>The GenAI Stack consists of:</p> <ul> <li>Application containers (the application logic in Python built with LangChain for the orchestration and Streamlit for the UI).</li> <li>Database container with vector index and graph search (Neo4j).</li> <li>LLM container Ollama (if you\u2019re on Linux). If you\u2019re on MacOS, install Ollama outside of Docker.</li> </ul> <p>These containers are tied together with Docker compose. Docker compose has a watch mode setup that rebuilds relevant containers any time you make a change to the application code, allowing for fast feedback loops and a good developer experience.</p>"},{"location":"lab1/solution/","title":"What problem does it solve","text":"<p>Generative AI (GenAI) is a type of artificial intelligence that can create new content, such as text, images, and music. It is still under development, but it has the potential to revolutionize many industries and solve a wide range of problems.</p> <p>Here are some of the problems that GenAI can solve:</p>"},{"location":"lab1/solution/#content-creation","title":"Content creation","text":"<p>GenAI can be used to create high-quality content at scale. This can be useful for businesses that need to produce a lot of content, such as marketing materials, blog posts, and social media posts. GenAI can also be used to create personalized content for each user, such as product recommendations and news feeds.</p>"},{"location":"lab1/solution/#data-augmentation","title":"Data augmentation","text":"<p>GenAI can be used to generate synthetic data, which can be used to train machine learning models and improve their performance. This is especially useful for applications where it is difficult or expensive to collect real-world data. Creative tasks: GenAI can be used to automate creative tasks, such as writing poetry, generating music, and designing images. This can free up human creativity for more complex and strategic tasks.</p>"},{"location":"lab1/solution/#problem-solving","title":"Problem solving","text":"<p>GenAI can be used to solve complex problems by generating creative solutions. For example, GenAI can be used to design new drugs, develop new products, and optimize business processes.</p> <p>GenAI is still in its early stages of development, but it has the potential to solve a wide range of problems and revolutionize many industries. Here are a few specific examples of how GenAI is being used today:</p>"},{"location":"lab1/solution/#marketing","title":"Marketing","text":"<p>GenAI is being used to create personalized marketing campaigns and generate targeted content for each user.</p>"},{"location":"lab1/solution/#media","title":"Media","text":"<p>GenAI is being used to create personalized news feeds and generate realistic synthetic media, such as videos and images.</p>"},{"location":"lab1/solution/#healthcare","title":"Healthcare","text":"<p>GenAI is being used to design new drugs, develop personalized treatment plans, and diagnose diseases.</p>"},{"location":"lab1/solution/#finance","title":"Finance","text":"<p>GenAI is being used to detect fraud, develop trading strategies, and optimize risk management.</p>"},{"location":"lab1/solution/#science","title":"Science","text":"<p>GenAI is being used to accelerate scientific research by generating new hypotheses and designing experiments.</p>"},{"location":"lab2/docker-developer-workflow/","title":"Docker Developer Workflow","text":""},{"location":"lab2/genai-stack/","title":"docker-genai-sample","text":"<p>A simple GenAI app for Docker's Docs based on the GenAI Stack PDF Reader application.</p> <p>The generative AI (GenAI) guide teaches you how to containerize an existing GenAI application using Docker. In this guide, you\u2019ll learn how to:</p> <ul> <li>Containerize and run a Python-based GenAI application</li> <li>Set up a local environment to run the complete GenAI stack locally for development</li> <li>Start by containerizing an existing GenAI application.</li> </ul>"},{"location":"lab2/genai-stack/#whats-this-sample-app-all-about","title":"What's this sample app all about?","text":"<p>The sample application used in this guide is a modified version of the PDF Reader application from the GenAI Stack demo applications. The application is a full stack Python application that lets you ask questions about a PDF file.</p> <p>The application uses LangChain for orchestration, Streamlit for the UI, Ollama to run the LLM, and Neo4j to store vectors.</p> <p>Clone the sample application. Open a terminal, change directory to a directory that you want to work in, and run the following command to clone the repository:</p> <pre><code>$ git clone https://github.com/ajeetraina/docker-genai-sample\n</code></pre> <p>You should now have the following files in your <code>docker-genai-sample</code> directory.</p> <pre><code>\u251c\u2500\u2500 docker-genai-sample/\n\u2502 \u251c\u2500\u2500 .gitignore\n\u2502 \u251c\u2500\u2500 app.py\n\u2502 \u251c\u2500\u2500 chains.py\n\u2502 \u251c\u2500\u2500 env.example\n\u2502 \u251c\u2500\u2500 requirements.txt\n\u2502 \u251c\u2500\u2500 util.py\n\u2502 \u251c\u2500\u2500 LICENSE\n\u2502 \u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"lab2/genai-stack/#initialize-docker-assets","title":"Initialize Docker assets","text":"<p>Now that you have an application, you can use <code>docker init</code> to create the necessary Docker assets to containerize your application. Inside the <code>docker-genai-sample</code> directory, run the <code>docker init</code> command. <code>docker init</code> provides some default configuration, but you'll need to answer a few questions about your application. For example, this application uses Streamlit to run. Refer to the following <code>docker init</code> example and use the same answers for your prompts.</p> <pre><code>$ docker init\nWelcome to the Docker Init CLI!\n\nThis utility will walk you through creating the following files with sensible defaults for your project:\n  - .dockerignore\n  - Dockerfile\n  - compose.yaml\n  - README.Docker.md\n\nLet's get started!\n\n? What application platform does your project use? Python\n? What version of Python do you want to use? 3.11.4\n? What port do you want your app to listen on? 8000\n? What is the command to run your app? streamlit run app.py --server.address=0.0.0.0 --server.port=8000\n</code></pre> <p>You should now have the following contents in your <code>docker-genai-sample</code> directory.</p> <pre><code>\u251c\u2500\u2500 docker-genai-sample/\n\u2502 \u251c\u2500\u2500 .dockerignore\n\u2502 \u251c\u2500\u2500 .gitignore\n\u2502 \u251c\u2500\u2500 app.py\n\u2502 \u251c\u2500\u2500 chains.py\n\u2502 \u251c\u2500\u2500 compose.yaml\n\u2502 \u251c\u2500\u2500 env.example\n\u2502 \u251c\u2500\u2500 requirements.txt\n\u2502 \u251c\u2500\u2500 util.py\n\u2502 \u251c\u2500\u2500 Dockerfile\n\u2502 \u251c\u2500\u2500 LICENSE\n\u2502 \u251c\u2500\u2500 README.Docker.md\n\u2502 \u2514\u2500\u2500 README.md\n</code></pre> <p>To learn more about the files that <code>docker init</code> added, see the following:  - Dockerfile  - .dockerignore  - compose.yaml</p>"},{"location":"lab2/genai-stack/#run-the-application","title":"Run the application","text":"<p>Inside the <code>docker-genai-sample</code> directory, run the following command in a terminal.</p> <pre><code>$ docker compose up --build\n</code></pre> <p>Docker builds and runs your application. Depending on your network connection, it may take several minutes to download all the dependencies. You'll see a message like the following in the terminal when the application is running.</p> <pre><code>server-1  |   You can now view your Streamlit app in your browser.\nserver-1  |\nserver-1  |   URL: http://0.0.0.0:8000\nserver-1  |\n</code></pre> <p>Open a browser and view the application at http://localhost:8000. You should see a simple Streamlit application. The application may take a few minutes to download the embedding model. While the download is in progress, Running appears in the top-right corner.</p> <p></p> <p>The application requires a Neo4j database service and an LLM service to function. If you have access to services that you ran outside of Docker, specify the connection information and try it out. If you don't have the services running, continue with this guide to learn how you can run some or all of these services with Docker.</p>"},{"location":"lab2/genai-stack/#starting-neo4j-container","title":"Starting Neo4j container","text":"<pre><code> docker run -d --name database -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/password neo4j:5.11\n</code></pre>"},{"location":"lab2/genai-stack/#starting-ollama-container","title":"Starting Ollama container","text":"<pre><code> docker run -d \\\n  --name ollama \\\n  -p 11434:11434 \\\n  -v ollama_volume:/root/.ollama \\\n  ollama/ollama:latest\n</code></pre>"},{"location":"lab2/genai-stack/#accessing-the-application","title":"Accessing the application","text":"<p>You can populate the form using the following values:</p> <pre><code>Neo4j URI - neo4j://192.168.1.3:7687\nNEO4J_USERNAME=neo4j\nNEO4J_PASSWORD=password\nOLLAMA_BASE_URL=http://host.docker.internal:11434\nOPENAI Key=&lt;add it here&gt;\n</code></pre>"},{"location":"lab2/genai-stack/#chatting-with-the-pdf","title":"Chatting with the PDF","text":""},{"location":"lab2/getting-started/","title":"Getting Started with Docker Init","text":"<p>Example used to demonstrate <code>docker init</code> CLI for a simple Hello World Python Program</p>"},{"location":"lab2/getting-started/#clone-the-repository","title":"Clone the repository","text":"<pre><code> git clone https://github.com/dockersamples/docker-init-demos\n cd docker-init-demos/python\n</code></pre>"},{"location":"lab2/getting-started/#run-the-application","title":"Run the application","text":"<p>You can simply use <code>python3 app.py</code> command.</p> <p>This code defines a handler that responds to GET requests with the specified text and starts an HTTP server listening on port 8080. When you run the script, you can access the server at http://localhost:8080 and see the same message as the Python program.</p> <p>Those commands will start a http server listening on port <code>8080</code>  and if your request <code>http://localhost:8080</code> you'll see the following output: </p> <pre><code>\u276f curl http://localhost:8080\n\n          ##         .\n## ## ##        ==\n## ## ## ## ##    ===\n/\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\\___/ ===\n{                       /  ===-\n\\______ O           __/\n \\    \\         __/\n  \\____\\_______/\n\n\nHello from Docker!\n</code></pre>"},{"location":"lab2/getting-started/#using-docker-init","title":"Using Docker init","text":""},{"location":"lab2/getting-started/#run-the-following-command","title":"Run the following command:","text":"<pre><code> docker init\n</code></pre> <p>This utility will walk you through creating the following files with sensible defaults for your project:   - .dockerignore   - Dockerfile   - docker-compose.yaml</p>"},{"location":"lab2/getting-started/#modify-the-dockerfile","title":"Modify the Dockerfile","text":"<pre><code>FROM python:3.8-alpine\nRUN mkdir /app\nADD . /app\nWORKDIR /app\nCMD [\"python3\", \"app.py\"]\n</code></pre>"},{"location":"lab2/getting-started/#modify-the-docker-compose-file","title":"Modify the Docker Compose file","text":"<pre><code>version: '3'\n\nservices:\n  app:\n    build: .\n    ports:\n      - \"8080:8080\"\n    command: python3 app.py\n</code></pre>"},{"location":"lab2/getting-started/#running-the-container-service","title":"Running the container service","text":"<pre><code> docker compose up -d --build\n</code></pre> <p>## Accessing the Python app</p> <p>``` curl localhost:8080</p> <pre><code>      ##         .\n## ## ##        ==\n</code></pre> <p>## ## ## ## ##    === /\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"_/ === {                       /  ===- ____ O           /               __/   _________/</p> <p>Hello from Docker! ```</p>"},{"location":"lab2/image-building/","title":"Docker Image Building and Best Practices","text":""},{"location":"lab2/image-building/#introducing-docker-init","title":"Introducing Docker Init","text":"<p>Introduced for the first time in Docker Desktop 4.18, the new docker init CLI generates Docker assets for projects, making it easier to create Docker images and containers. When you run the docker init command in your project directory, it will guide you through the creation of the necessary files for your project with sensible defaults. These files include:</p> <pre><code>.dockerignore\nDockerfile\ndocker-compose.yaml\n</code></pre> <p>The docker init command also allows you to choose the application platform that your project uses and the relative directory of your main package. </p>"},{"location":"lab2/image-building/#whos-this-for","title":"Who\u2019s this for?","text":"<p>This feature is targeted at developers who want to quickly create and manage Docker assets without having to manually configure everything. </p> <p>Note: Currently, the CLI is in beta phase. </p>"},{"location":"lab2/image-building/#benefits-of-docker-init","title":"Benefits of Docker Init","text":"<p>The advantages of using the docker init command include:</p> <ul> <li>Simplified Docker asset creation: The command streamlines the creation of necessary Docker files, reducing the chances of errors and ensuring that best practices are followed.</li> <li>Saves time and effort: With the default settings and guided prompts, users can quickly create Docker assets without the need for extensive knowledge of Docker or its syntax.</li> <li>Better project organization: The generated files provide a standardized and organized structure for the project, making it easier for developers to maintain and update the project over time.</li> <li>Enhanced portability: By using Docker assets, projects become more portable across different environments, making it easier to move the project from development to production.</li> </ul> <p></p>"},{"location":"lab2/inner-loop-developer/","title":"Inner-loop Developer Workflow","text":""},{"location":"lab2/what-is-docker/","title":"What is Docker","text":"<p>Developing apps today requires so much more than writing code. Multiple languages, frameworks, architectures, and discontinuous interfaces between tools for each lifecycle stage creates enormous complexity. Docker simplifies and accelerates your workflow, while giving developers the freedom to innovate with their choice of tools, application stacks, and deployment environments for each project.</p> <p>In 2013, Docker introduced what would become the industry standard for containers. Containers are a standardized unit of software that allows developers to isolate their app from its environment, solving the \u201cit works on my machine\u201d headache. For millions of developers today, Docker is the de facto standard to build and share containerized apps \u2013 from desktop, to the cloud. We are building on our unique connected experience from code to cloud for developers and developer teams.</p> <p>Docker has been around for over 10-years. We started in the container space focused on making it easier for organizations to modernize with container technology. Over the years we have evolved our initial offering to meet the needs of modern developers, focusing on enabling developers to build container based applications locally. </p>"},{"location":"lab2/what-is-docker/#overview-of-docker-desktop","title":"Overview of Docker Desktop","text":"<p>Docker Desktop is the easiest way for developers using containers in production to edit, run, test, and share containerized apps locally on Linux, Windows, and macOS machines. Docker Desktop works out-of-the-box \u2014 meaning it comes with the entire environment needed to develop and run Linux, Windows, and macOS containers locally (on the developer\u2019s laptop). Docker Desktop also handles many of the tedious and complex tasks associated with setting up containers. This allows developers to continue focusing on what they love and do best \u2014 writing code \u2014 instead of spending hours setting up and maintaining Docker locally (i.e., updating the VM, networking, and file sharing mapping between the host and the VM and all the tooling needed to run Docker locally). </p>"},{"location":"lab2/what-is-docker/#docker-is-focused-on-developer-success","title":"Docker is focused on Developer Success","text":"<p>Docker Desktop is a powerful tool designed to simplify and streamline the development and deployment of applications using Docker containers. Let's break down the key points mentioned in the description:</p> <p></p>"},{"location":"lab2/what-is-docker/#speed","title":"Speed","text":"<p>Docker Desktop helps developers maximize their productivity by reducing the time spent on setup and configuration. With Docker, developers can easily package their applications and all their dependencies into containers, allowing for a consistent and reproducible development environment. This eliminates the need for complex manual setups and ensures that everyone on the team can have the same development environment, minimizing the setup overhead.</p>"},{"location":"lab2/what-is-docker/#security","title":"Security","text":"<p>Docker Desktop is designed to provide non-intrusive and actionable security features. It allows developers to identify and address security vulnerabilities during the development process, known as the \"inner loop,\" rather than waiting for later stages like continuous integration (CI) or production. Docker also provides features like container isolation, which enhances security by ensuring that applications run in isolated environments with restricted access to the host system.</p>"},{"location":"lab2/what-is-docker/#choice","title":"Choice","text":"<p>Docker Desktop empowers developers with the freedom to explore and experiment with various technologies. Docker's containerization approach allows developers to use different tools and technologies for different parts of their applications without conflicts or compatibility issues. Developers are not limited to monolithic and \"one-size-fits-all\" development environments; instead, they can choose the best tools for their specific use cases. Overall, Docker Desktop's features cater to developers' needs for a fast and efficient development process, enhanced security practices, and the flexibility to use diverse technologies based on the requirements of their projects. This combination of speed, security, and choice makes Docker Desktop a popular choice among developers looking to containerize and manage their applications effectively.</p>"},{"location":"lab6/using-docker-compose/","title":"Using Docker Compose","text":"<p>Follow the instructions to run a complete GenAI Stack using Docker Compose</p>"},{"location":"lab6/using-docker-compose/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Pre-req</li> <li>Step 1. Install Ollama on Mac OS</li> <li>Step 2. Create OpenAI Secret API Keys</li> <li>Step 3. Sign up for LangChain Beta for API Keys</li> <li>Step 4. Clone the GenAI Repo</li> <li>Step 5. Create .env file</li> <li>Step 6. Bring up Compose Services</li> <li>Step 7. Viewing the services on Docker Dashboard</li> <li>Step 8. Accessing the app</li> <li>Step 9. Accessing the Neo4j </li> <li>Step 10. Accessing GenAI Stack PDF Bot </li> </ul>"},{"location":"lab6/using-docker-compose/#prereq","title":"Prereq","text":"<ul> <li>Install Docker Desktop 4.23.0</li> </ul>"},{"location":"lab6/using-docker-compose/#step-1-install-ollama-on-mac-os","title":"Step 1. Install Ollama on Mac OS","text":"<p>Visit this link to download and install Ollama on Macbook. Please note that currently, Windows is not supported by Ollama, so Windows users need to generate a OpenAI API key and configure the stack to use gpt-3.5 or gpt-4 in the .env file.</p> <p></p> <p>Choose your preferrable operating system. </p> <p></p>"},{"location":"lab6/using-docker-compose/#step-2-create-openai-secret-api-keys","title":"Step 2. Create OpenAI Secret API Keys","text":"<p>Visit this link to create your new OpenAI Secret API Keys.</p>"},{"location":"lab6/using-docker-compose/#step-3-sign-up-for-langchain-beta-for-api-keys","title":"Step 3. Sign Up for LangChain Beta for API Keys","text":"<p>Visit this link in order to create Langchain Endpoint and API Keys. You will need the following information</p> <pre><code>LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\nLANGCHAIN_TRACING_V2=true # false\nLANGCHAIN_PROJECT=default\nLANGCHAIN_API_KEY=ls__cbabccXXXXXX\n</code></pre>"},{"location":"lab6/using-docker-compose/#step-4-clone-the-repository","title":"Step 4. Clone the repository","text":"<pre><code> git clone https://github.com/docker/genai-stack\n cd genai-stack\n</code></pre>"},{"location":"lab6/using-docker-compose/#step-5-create-env-file","title":"Step 5. Create .env file","text":"<pre><code>cat .env \nOPENAI_API_KEY=sk-EsNJzI5uMBCXXXXXXXX\nOLLAMA_BASE_URL=http://host.docker.internal:11434\nNEO4J_URI=neo4j://database:7687\nNEO4J_USERNAME=neo4j\nNEO4J_PASSWORD=password\nLLM=llama2 #or any Ollama model tag, or gpt-4 or gpt-3.5\nEMBEDDING_MODEL=sentence_transformer #or openai or ollama\n\nLANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\nLANGCHAIN_TRACING_V2=true # false\nLANGCHAIN_PROJECT=default\nLANGCHAIN_API_KEY=ls__cbabccXXXXXX\n</code></pre> <p>Don't forget to change \"localhost\" to \"database\" under NEO4J_URI entry.</p>"},{"location":"lab6/using-docker-compose/#step-6-bring-up-compose-services","title":"Step 6. Bring up Compose services","text":"<pre><code> docker compose up -d --build\n</code></pre> <pre><code>..\n..\ngenai-stack-bot-1         |   You can now view your Streamlit app in your browser.\ngenai-stack-bot-1         |\ngenai-stack-bot-1         |   URL: http://0.0.0.0:8501\ngenai-stack-bot-1         |\ngenai-stack-pdf_bot-1     |\ngenai-stack-pdf_bot-1     |   You can now view your Streamlit app in your browser.\ngenai-stack-pdf_bot-1     |\ngenai-stack-pdf_bot-1     |   URL: http://0.0.0.0:8503\ngenai-stack-pdf_bot-1     |\ngenai-stack-loader-1      |\ngenai-stack-loader-1      |   You can now view your Streamlit app in your browser.\ngenai-stack-loader-1      |\ngenai-stack-loader-1      |   URL: http://0.0.0.0:8502\ngenai-stack-loader-1      |\n</code></pre>"},{"location":"lab6/using-docker-compose/#step-7-viewing-the-services-on-docker-dashboard","title":"Step 7. Viewing the Services on Docker Dashboard","text":""},{"location":"lab6/using-docker-compose/#step-8-accessing-the-app","title":"Step 8. Accessing the app","text":"<p>Visit http://0.0.0.0:8502 to access the following:</p> <p></p> <p>Click \"Import\". It will take a minute or two to run the import. Most of the time is spent generating the embeddings. After or during the import you can click the link to <code>http://localhost:7474</code> and log in with username \u201cneo4j\u201d and password \u201cpassword\u201d as configured in docker compose. There, you can see an overview in the left sidebar and show some connected data by clicking on the \u201cpill\u201d with the counts.</p> <p>The data loader will import the graph using the following schema.</p> <p></p>"},{"location":"lab6/using-docker-compose/#result","title":"Result:","text":"<p>The graph schema for Stack Overflow consists of nodes representing Questions, Answers, Users, and Tags. Users are linked to Questions they\u2019ve asked via the \u201cASKED\u201d relationship and to Answers they\u2019ve provided with the \u201cANSWERS\u201d relationship. Each Answer is also inherently associated with a specific Question. Furthermore, Questions are categorized by their relevant topics or technologies using the \u201cTAGGED\u201d relationship connecting them to Tags.</p>"},{"location":"lab6/using-docker-compose/#step-9-accessing-the-neo4j","title":"Step 9. Accessing the Neo4j","text":"<p>As instructed, open <code>http://localhost:7474</code> and log in with username \u201cneo4j\u201d and password \u201cpassword\u201d as configured in docker compose.</p> <p></p>"},{"location":"lab6/using-docker-compose/#step-10-query-the-imported-data-via-a-chat-interface-using-vector-graph-search","title":"Step 10. Query the Imported Data via a Chat Interface Using Vector + Graph Search","text":"<p>This application server on <code>http://localhost:8501</code> has the classic LLM chat UI and lets the user ask questions and get answers.</p> <p>There\u2019s a switch called RAG mode where the user can rely either completely on the LLMs trained knowledge (RAG: Disabled), or the more capable (RAG: Enabled) mode where the application uses similarity search using text embedding and graph queries to find the most relevant questions and answers in the database.</p> <p>Click \"Highly ranked questions\"</p>"},{"location":"lab6/using-docker-compose/#step-11-accessing-genai-stack-pdf-bot","title":"Step 11. Accessing GenAI Stack PDF Bot","text":"<p>Open <code>http://0.0.0.0:8503/</code> on the browser to access the PDF Bot that allows you to chat with your PDF file.</p> <p></p> <p>In order to test drive, I uploaded my latest resume and asked a quick question.  It responded back with the right answer. Amazing !!</p>"},{"location":"prereq/prerequisites/","title":"Prerequisites:","text":"<p>Download and Install Docker Desktop on your system.</p> <ul> <li>Apple Chip</li> <li>Intel Chip</li> <li>Windows</li> <li>Linux</li> </ul>"},{"location":"prereq/prerequisites/#enabling-wsl-2-based-engine-on-docker-desktop-for-windows","title":"Enabling WSL 2 based engine on Docker Desktop for Windows","text":"<p>In case you're using Windows 11, we recommend you to install Docker Desktop for Windows. Also, you will need to enable WSL 2 by opening Docker Desktop &gt; Settings &gt; Resources &gt; WSL Integration</p> <p></p>"}]}